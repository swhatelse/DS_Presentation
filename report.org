#+TITLE: In Search of an Understandable Consensus Algorithm
#+AUTHOR: Steven QUINITO MASNADA
#+LaTeX_CLASS: article
#+LaTeX_CLASS_OPTIONS: [margin=0.5in]
#+OPTIONS: toc:nil

* Introduction
  Paxos is the most known consensus algorithm but it is very difficult
  to understand. Only few people master it. Moreover its architecture
  is not suited for most real systems. It results an implementation
  that is a different version of Paxos and this one has not been
  proved. The purpose of Raft is to be an alternative to (multi-)Paxos
  but easier to understand allowing to develop the intuition more
  easily. This way people can more easily implement it and adapt it to
  their needs.
* Raft
** Design
   The main goal of Raft is the understandability and all design 
   choices have been made with that in mind. As opposed to Paxos, the
   problem has been splitted into different sub-problems that can be
   understand independently. The nodes are assumed to be fail stop and
   non-bizantine.
   # Raft follows the general principles of
   # replicated state machines  to ensure the consistency of the
   # logs. The servers get requests from clients, agree on the  order,
   # append them to their logs, process the logs and return the result
   # to the client.  
   # Missing fail stop & non-bizantine

   In Raft the servers can have three different states which are
   leader, candidate and follower. All the requests are handled by one
   server (the leader) which replicates the logs among the others (the
   followers). As a result, all the decision about the logs are taken
   on one server, thus it is easier to manage the consistency of the
   logs. The candidate state is used for the election of leader. 
   
   The time is divided in terms and each term start with an election and
   lasts until the next election. They are used as logical clock for
   the election and logs replication. 
** Leader election
   Each follwer has a timeout that trigger an election by
   transitionning into the candidate state. A candidate  increments
   the term number and requests votes from the others. 
   
   To win an election a candidate musts gather the majority of the
   votes. A node can vote for only one candidate per term it ensure
   that only one leader can be elected.

   Once a candidate wins an election it becomes leader and sends an
   heartbeat to establish its authority. As long as the leader is up
   it sends an heartbeat frequently to reset the timeout of the
   followers. 

   It is possible to have split votes without winning majority when
   many nodes trigger an election a the same time. The likelyhood of
   this situation is reduced by using random timeout. And in case of
   split votes candidates also have timeout.

** Logs replication
   Requests from clients are handled only by the leader. It appends
   the entry to its logs and then send it to all the followers. When a
   log has been replicated on the majority it is committed and
   processed by a state machine. The leader check its consistency with
   the followers using the term number and the log index. For
   followers that are not consistents, it finds the moment when they
   started diverging, and overwrites their logs. 
   # The leader cannot overwrite its own logs and committed logs.
   # All committed log must be the same on all the machine
   # A server is update to if it the committed logs are the same as the others

** Safety                                                          :noexport:
   The leader election and logs replication mechanism are not enough
   to ensure the integrity of the logs it must be coupled with other
   restrictions.

   First, a candadite cannot be elected if its logs are not at least as
   up-to-date as the majority.

   Second, the leader completeness ensure that a log entry committed in a
   given term will be present in the log of leaders of higher terms.
** Membership changes
   Raft uses a transition phase to switch from an old (C_old)
   configuration to a new one (C_new) because it is not safe to switch
   directly go from C_old to C_new. It is called the the joint
   consensus. In the transition phase (C_old,C_new), C_old and C_new
   coexist and can make decisions about election and log
   commitment. In general it is not the case in other change
   configuration mechanism, in fact, in the transition phase, no
   request are handled, decisions are suspended. 

   # Maybe I missed the most fundamental part.
   # Yeah this part can be ommitted
   # With the election mechanism on view change it is possible to have
   # two leader elected at the same at time as the switch between the
   # view cannot happen at exactly the same time for all the
   # servers. Raft resolves this problem using the /joint consensus/ which
   # a two-phase approach. When a server join in, it may not have any
   # logs, recovering can be long and it may prevent logs from being
   # committed. To avoid this, raft allows the server to /pre-join/ as a
   # non voting server. 
   
   # Another problem, is that removed servers will not received
   # heartbeats and will trigger an election. The other servers will see
   # an election with a term number higher than their they will vote and
   # the current leader will transition to follower state. This process
   # can repeat indefinitively because, removed server will never get
   # any heartbeats. 
   # Solution missing
* Evaluation
** Understandability
   To measure the understandabilty if Raft, they took students from
   Stanford University and U.C. Berkeley, taught them Paxos and Raft
   and made them pass a test. As expected, students had more success
   with questions about Raft than Paxos. This means they successfully
   achieved the goal of making a more understandable consensus
   algorithm.
** Perfomances
   Regarding the perfomances, there are three important points. First
   one is the logs replication, it is assumed efficient because it
   uses the minimum number of messages.

   The second point is the for the election to converge. In the best
   case, it takes the time for a process to timeout, the time to send
   the vote request to all the servers and the time to receive
   acknowledgment from the majority. But the election could take more
   time if splitted votes occur. To avoid the likelyhood of this
   scenario Raft uses randomness for the timeout.

   The third point is the down time of the system. During time between
   which a leader crashes and a new on is elected the system cannot
   take request from clients. Thus the down time dependent on the
   duration of the election timeout. The shorter it is the more
   available the system is. But a too small timeout will trigger
   unnecessary election.  
* Conclusion
  As can be seen with Raft, they succeed in making a more
  understandable consensus algorithm than Paxos. People can more
  easily have the intuition and more easily implement real systems on
  top of it. But does it scale well? They did not mention how many
  servers they used for their tests. We saw that randomness for the
  timeout election reduces the probability of split votes and allows
  the election to converge. But if there are lots of servers the
  probability of split votes will be high so we need to use bigger 
  timeouts. Hence it will increase the down time. With lots of nodes
  does the down time still acceptable?

